{
    "last_node_id": 22,
    "last_link_id": 23,
    "nodes": [
        {
            "id": 10,
            "type": "KSampler",
            "pos": [
                1586.9149157825411,
                542.4579216217965
            ],
            "size": {
                "0": 315,
                "1": 262
            },
            "flags": {},
            "order": 9,
            "mode": 0,
            "inputs": [
                {
                    "name": "model",
                    "type": "MODEL",
                    "link": 10
                },
                {
                    "name": "positive",
                    "type": "CONDITIONING",
                    "link": 11
                },
                {
                    "name": "negative",
                    "type": "CONDITIONING",
                    "link": 12
                },
                {
                    "name": "latent_image",
                    "type": "LATENT",
                    "link": 13
                }
            ],
            "outputs": [
                {
                    "name": "LATENT",
                    "type": "LATENT",
                    "links": [
                        16
                    ],
                    "slot_index": 0
                }
            ],
            "properties": {
                "Node name for S&R": "KSampler"
            },
            "widgets_values": [
                156680208700286,
                "randomize",
                20,
                8,
                "euler",
                "normal",
                1
            ]
        },
        {
            "id": 12,
            "type": "EmptyLatentImage",
            "pos": [
                1196.9149157825411,
                965.4579216217965
            ],
            "size": {
                "0": 315,
                "1": 106
            },
            "flags": {},
            "order": 0,
            "mode": 0,
            "outputs": [
                {
                    "name": "LATENT",
                    "type": "LATENT",
                    "links": [
                        13
                    ],
                    "slot_index": 0
                }
            ],
            "properties": {
                "Node name for S&R": "EmptyLatentImage"
            },
            "widgets_values": [
                512,
                512,
                1
            ]
        },
        {
            "id": 13,
            "type": "CLIPTextEncode",
            "pos": [
                1138.9149157825411,
                542.4579216217965
            ],
            "size": {
                "0": 422.84503173828125,
                "1": 164.31304931640625
            },
            "flags": {},
            "order": 5,
            "mode": 0,
            "inputs": [
                {
                    "name": "clip",
                    "type": "CLIP",
                    "link": 14
                }
            ],
            "outputs": [
                {
                    "name": "CONDITIONING",
                    "type": "CONDITIONING",
                    "links": [
                        11
                    ],
                    "slot_index": 0
                }
            ],
            "properties": {
                "Node name for S&R": "CLIPTextEncode"
            },
            "widgets_values": [
                "beautiful scenery nature glass bottle landscape, , purple galaxy bottle,"
            ]
        },
        {
            "id": 14,
            "type": "CLIPTextEncode",
            "pos": [
                1136.9149157825411,
                745.4579216217965
            ],
            "size": {
                "0": 425.27801513671875,
                "1": 180.6060791015625
            },
            "flags": {},
            "order": 6,
            "mode": 0,
            "inputs": [
                {
                    "name": "clip",
                    "type": "CLIP",
                    "link": 15
                }
            ],
            "outputs": [
                {
                    "name": "CONDITIONING",
                    "type": "CONDITIONING",
                    "links": [
                        12
                    ],
                    "slot_index": 0
                }
            ],
            "properties": {
                "Node name for S&R": "CLIPTextEncode"
            },
            "widgets_values": [
                "text, watermark"
            ]
        },
        {
            "id": 15,
            "type": "VAEDecode",
            "pos": [
                1932.9149157825411,
                544.4579216217965
            ],
            "size": {
                "0": 210,
                "1": 46
            },
            "flags": {},
            "order": 11,
            "mode": 0,
            "inputs": [
                {
                    "name": "samples",
                    "type": "LATENT",
                    "link": 16
                },
                {
                    "name": "vae",
                    "type": "VAE",
                    "link": 17
                }
            ],
            "outputs": [
                {
                    "name": "IMAGE",
                    "type": "IMAGE",
                    "links": [
                        18
                    ],
                    "slot_index": 0
                }
            ],
            "properties": {
                "Node name for S&R": "VAEDecode"
            }
        },
        {
            "id": 16,
            "type": "SaveImage",
            "pos": [
                2174.9149157825414,
                545.4579216217965
            ],
            "size": {
                "0": 210,
                "1": 58
            },
            "flags": {},
            "order": 12,
            "mode": 0,
            "inputs": [
                {
                    "name": "images",
                    "type": "IMAGE",
                    "link": 18
                }
            ],
            "properties": {},
            "widgets_values": [
                "ComfyUI"
            ]
        },
        {
            "id": 20,
            "type": "Bedrock - Prompt Enhancer",
            "pos": [
                827.9149157825411,
                8.457921621796459
            ],
            "size": {
                "0": 392.4112854003906,
                "1": 213.85800170898438
            },
            "flags": {},
            "order": 7,
            "mode": 0,
            "inputs": [
                {
                    "name": "prompt",
                    "type": "STRING",
                    "link": 21,
                    "widget": {
                        "name": "prompt"
                    }
                },
                {
                    "name": "base_prompt",
                    "type": "STRING",
                    "link": 22,
                    "widget": {
                        "name": "base_prompt"
                    }
                }
            ],
            "outputs": [
                {
                    "name": "STRING",
                    "type": "STRING",
                    "links": [
                        20
                    ],
                    "slot_index": 0
                }
            ],
            "properties": {
                "Node name for S&R": "Bedrock - Prompt Enhancer"
            },
            "widgets_values": [
                "",
                "0:01\nhello everyone this is Amon here from\n0:03\nflow scale and in this video I'm going\n0:07\nto be talking about uh IC light\n0:10\nsomething that has recently just come up\n0:12\nin uh uh and sort of is taking a lot of\n0:16\npeople by uh surprise because something\n0:19\nnow is possible which was not really\n0:22\npossible with\n0:24\num with a a stable diffusion which is to\n0:28\nbe able to adjust light in a fashion\n0:30\nthat is very\n0:32\nrealistic now uh we let's deep Let's uh\n0:35\ndig deep into that in this video but\n0:37\nbefore that uh uh if you want to reach\n0:40\nme out you can find me on Twitter with @\n0:42\nnerdycap\n0:44\n007 and uh I usually post about uh comfy\n0:48\nand uh uh how to work around comfy\n0:51\noptimizations on comfy and a lot of\n0:53\ninteresting stuff so let's get into\n0:57\nit so comfy you u i has this new even\n1:02\nbefore we lap into comfy UI let's talk\n1:06\nabout IC light\n1:09\nfirst so what is icite uh icite is a\n1:12\nproject to manipulate the illuminations\n1:14\nof image you can uh illuminate an image\n1:16\nin different fashion and uh not only\n1:19\nthat uh it is um it allows you to you\n1:23\nknow sort of add backgrounds and uh do\n1:25\nstuff with uh of by fixing a foreground\n1:28\nit it allows you to you know add\n1:30\nbackground and do a lot of stuff over\n1:31\nthere so to just give you an example\n1:35\nlike uh let's say this is an input image\n1:39\nuh you uh it automatically takes the\n1:41\nforeground out and uh uh uh based on the\n1:45\nprompt that you have provided and the\n1:46\ndirectional uh light that you have\n1:48\nprovided you can generate this sort of\n1:51\nimage now we'll experiment more with it\n1:55\num right now it has been launched on uh\n1:58\nboth on hugging phas and also on GitHub\n2:01\nthere are three models over here uh this\n2:05\none the FC IC light uncore sd15 uncore\n2:10\nfc. safe tensors is the one which is the\n2:13\nbest performing\n2:15\nmodel so we will uh use that across but\n2:19\nuh let's go through their um uh hugging\n2:22\nface space let's let's try this out\n2:25\nbefore we uh move on to comfy UI\n2:30\nso let me let me pick an image whom\n2:33\nshall we try let's try Jason mumua I\n2:36\nhave an image of Jason mumua\n2:38\nhere let's try Right\n2:41\nlight okay so they also have a few\n2:46\num uh options to select out of here\n2:49\nwhere which you can use as an example uh\n2:52\nbut let's let's see I I want to try\n2:54\nsomething on my own though\n2:58\num\n3:00\nman standing on a\n3:04\nbeach uh soft\n3:07\nsunlight I have put Right light let's\n3:10\nlet's try to relight this\n3:31\nvery\n3:33\ninteresting now if you take a look uh\n3:37\nthe light is so natural as if it's a\n3:40\nit's an image which was uh you know shot\n3:42\non a\n3:43\nbeach but uh there are a few like\n3:47\ndrawbacks to this process uh if you see\n3:50\nlike the distortions are happening a\n3:52\nlittle bit on the face and it's changing\n3:54\nthe details to some level although I I\n3:57\nmean real big kudos to\n4:00\nthe way they are uh still maintaining\n4:03\nthe details probably I guessing there's\n4:06\na\n4:07\ngood um sort of effort gone into just\n4:11\nretaining the details now this uh look\n4:14\nat this the hair and every everything is\n4:17\nso natural here the now right now these\n4:21\ndetails maybe are changing a little bit\n4:24\nbut I'm pretty much sure in the in the\n4:26\nuh in the uh later versions with of IC\n4:29\nlight we are going to be seeing like\n4:30\nreally amazing progress\n4:32\nthere so let's let's try a few few more\n4:36\nthings um and\n4:38\nstanding\n4:40\nin a living\n4:43\nroom um soft sunlight Through the\n4:48\nWindows coming through the\n4:51\nwindows let's let's put uh left light\n4:54\nthis time let's try\n5:05\no\n5:06\nnice but you can see uh the details of\n5:09\nthe clothing are changing like uh more\n5:13\nthan the details the coloring of the\n5:14\nclothing are\n5:15\nchanging so as as I already said like\n5:19\nit's\n5:20\nretaining things to a good level but\n5:23\nstill there is um there is a lot of\n5:27\nimprovement that needs to happen in\n5:29\nterms of uh retaining the identity to uh\n5:34\nits\n5:36\nfullest um they also like have a bunch\n5:39\nof examples you can try out here where\n5:42\nuh\n5:43\nthe they also have the seed and\n5:45\neverything here but uh so these I\n5:48\ngenerally when I try out uh um any new\n5:53\nuh you know uh space or any new model\n5:56\nthat gets launched I don't don't try\n5:58\nthere uh generic test data because it's\n6:02\nit's their best performing data you\n6:04\nalready know that right so it's better\n6:06\nto try out on your own uh inputs and uh\n6:09\nsee the uh how how exactly is the model\n6:13\nperforming so uh I think that's pretty\n6:16\nmuch it there are a few more options\n6:19\nAdvanced options here you can move\n6:21\naround the steps more steps let's maybe\n6:23\ntry\n6:24\nwith um 30\n6:30\n35 maybe let's let's try with\n6:34\n35 I don't usually go above 30 because\n6:37\nuh 30 is like enough uh for the number\n6:42\nof steps usually for me but let's\n6:45\nsee I'm just trying to see if uh we can\n6:49\nretain the these details which I'm\n6:51\ntalking about if we increase the steps\n6:53\nmaybe it retains it more who knows but\n6:57\nsee working with stable diffusion or any\n6:59\nuh thing like that is like uh shooting\n7:02\nan arrow in the dark but as you can see\n7:05\nlike it's again not retaining the\n7:08\nuh um the clothing but clothing not\n7:12\nbeing retained can be fixed a little bit\n7:14\nto a good certain uh level so if I um if\n7:18\nI go here and let me let me put pull\n7:22\nthis image out man standing in a living\n7:25\nroom um okay let's let's go through the\n7:28\nsame one actually let me relight this\n7:38\ndude oh my God\n7:41\nokay this is another uh issue here as\n7:45\nwell like it's darkening the uh the\n7:49\nperson the foreground a lot I don't know\n7:51\nhow to fix that\n7:53\nhere okay but but uh now if you see the\n7:57\nimage the the the the t-shirt is getting\n7:59\na little whitish over here let's let's\n8:01\ntry adding\n8:08\nthat actually yellow shirt um and black\n8:13\npants let's try adding\n8:26\nthat there you go uh so as you see right\n8:30\nuh you can do a lot of stuff like you\n8:32\ncan do uh um uh if there's a major use\n8:37\ncase of this in\n8:39\nfashion uh industry uh I mean the output\n8:43\nright now which you're seeing I'm pretty\n8:45\nmuch sure they are using an SD 1.5 model\n8:48\nat this point I guess I can just tell\n8:50\nfrom seeing the outputs but uh and also\n8:53\nwe are also using SD 1.5 in the comi\n8:56\nworkflows that I'm going to be showing\n8:58\nyou right after this but uh the the\n9:03\noutput uh here is good it is retaining\n9:06\nthe details the the texture and the\n9:09\nstructure of uh the clothing and the\n9:12\nperson uh as if it would happen like if\n9:15\nyou are using canny Edge detector to a\n9:18\nvery good level this something like this\n9:20\nyou would\n9:21\nsee but uh it's still changing the\n9:24\ndetails a little bit I'm pretty much\n9:26\nsure that will also improve as I already\n9:28\nsaid but uh\n9:30\nyou see right to a good level you can\n9:32\nsolve these issues by specifying the\n9:35\ncolor of the shirt pant and you know\n9:37\nspecific\n9:38\ndetails but um yeah there's a there's a\n9:43\nchance you will hit a roadblock uh when\n9:46\nwhen it's like any any sort of complex\n9:49\nclothing uh that's where you will hit a\n9:51\nroadblock\n9:52\nhere okay so let's see how we can use\n9:57\nthis in our comfy workflows what can we\n10:00\ndo here so to move on to the comfy side\n10:04\nI want to show you the\n10:07\ncomfy node that we're going to be using\n10:10\nit's comfy UI IC\n10:12\nlight and it is like uh pretty new 3 4\n10:17\ndays ago or probably last week people\n10:20\nhave been working on this very very new\n10:23\nso and they also specified some of the\n10:26\nexample workflows require the very\n10:28\nlatest featur features in KJ nodes so if\n10:31\nif you try out their example workflows\n10:34\nprobably just have KJ nodes I also have\n10:36\ninstalled KJ nodes it is mostly used for\n10:40\nthis uh lighting setup I'll show you\n10:42\nthat\n10:44\num yeah so let's let's uh dig deep into\n10:47\nthis I've already set up a a workflow\n10:50\nwhich I'll attach in the description of\n10:52\nthis video you can go through that and\n10:55\nlet's uh let's try to see what what we\n10:57\ncan achieve here\n11:00\nso uh just to explain the workflow uh\n11:03\nthis is the input image which I am\n11:05\ntaking in and uh first of all I'm using\n11:09\nuh image remg uh for removing the\n11:12\nbackground and just isolating the\n11:14\nforeground and uh after that that image\n11:18\nis being resized while also keeping\n11:21\nproportions which is very important if\n11:24\nyou lose the proportion it'll be well\n11:26\nyou'll lose the proportion so\n11:30\num uh after that this aspect resize mask\n11:35\nis coming from the mask area of this\n11:38\nI'll show you how exactly am I using\n11:41\nthis and then uh the output from this\n11:43\nthe mask that is being created is going\n11:44\ninto grow mask with blur these two nodes\n11:47\nare from KJ nodes and then we are\n11:49\nconverting it uh converting The Mask to\n11:52\nimage just to show case\n11:56\nhere and uh uh to Showcase here and also\n12:00\nwe are putting that in vaen code here\n12:03\nwhich is eventually going into a k\n12:05\nsampler\n12:08\nnow apart from that uh we are also using\n12:13\nas a base model we are using epic\n12:15\nrealism SD 1.5 model which is this\n12:19\nmodel the uh one uh which has been there\n12:24\nfor a while now\n12:27\nand that I'm connecting\n12:29\nto the load and apply IC light uh node\n12:35\nin which we are loading uh the sd15 FC\n12:39\nyou can download this uh uh uh this and\n12:42\nalso there is IC light conditioning you\n12:44\ncan download these models in uh um\n12:46\ncustom nodes right out of comfy so if\n12:49\nyou open comfy and uh let me check out\n12:52\nsee IC light uh if you just search IC\n12:55\nhyphen light you can find out this node\n12:57\ncomi IC light and you can directly\n12:59\ninstall this and if you want to install\n13:03\nthe models you can go and search I see\n13:07\nlight uh and you'll find all the three\n13:10\nmodels all three models have different\n13:12\npurposes but uh I generally I'm using uh\n13:16\nthe one which has FC because uh it's\n13:20\nwritten on their GitHub page that that's\n13:22\nthe one which is the most uh best\n13:24\nperforming uh model out of their uh uh\n13:27\ndifferent uh options\n13:32\nso uh the multiplier uh I'm not very\n13:35\nsure what exactly does it do but uh what\n13:39\nI found is like around. 2 183 or\n13:42\nwhatever at that uh uh number it's\n13:45\nworking decently\n13:48\nfine um there are some negative uh\n13:52\nnegative embeddings and negative uh um\n13:55\nuh prompts that I've given here and also\n13:57\nsome positive prompts which I have\n13:59\nconnected here uh\n14:02\nhere and\n14:04\neventually the K sampler throws an\n14:06\noutput VA decodes VA decode happens and\n14:10\nyou see the output here okay now let's\n14:12\ntry uh running with this also one more\n14:16\nuh thing which you won't find in the uh\n14:20\nin the uh hugging face space demo is\n14:23\nthat uh I have also introduced a IP\n14:26\nadapter here so that is a a good thing\n14:29\nuh that we can do like that's that's the\n14:32\ngood thing about comfi you have a lot of\n14:34\nfreedom in comi you can do a lot of\n14:35\nstuff so right now what I'm doing here\n14:37\nis I have introduced\n14:39\na uh IP adapter for uh giving a\n14:43\nreference image for the background right\n14:46\nso uh I'm doing something like that now\n14:48\nthis is not the traditional way to uh do\n14:51\nthe background based uh relighting on uh\n14:55\nIC light there is a separate way to uh\n14:59\nproperly uh you know uh overlay\n15:02\nsomething on a background but the\n15:04\nproblem in this is it just you know puts\n15:06\nthe person the foreground on this back\n15:09\nit takes this as a background and this\n15:11\ntakes this as a foreground and just puts\n15:13\nit on top of this right so I mean that\n15:18\nis doable but eventually it will look\n15:20\nquite fake to be very honest so uh but\n15:24\nbut the good thing is this is if you if\n15:27\nyou really look at it this is like in\n15:29\npainting on\n15:30\nsteroids because in painting so far has\n15:33\nbeen only\n15:35\num uh this is not particularly in\n15:38\npainting this is more like cut uh\n15:40\ncutting and pasting by mask or so in the\n15:43\nprevious previous uh you know uh uh um\n15:48\niterations if you if you did something\n15:50\nyou would be doing cutting and pasting\n15:52\nby mask but right now um you can do it\n15:56\nwith the lighting and everything in\n15:57\nplace this is so awesome otherwise what\n16:00\nusually used to happen is you cut by\n16:01\nmask and paste this dude here and then\n16:04\nyou run a k sampler on top of the final\n16:06\noutput uh final image to with a very\n16:09\nless denoising strength to make it as if\n16:11\nyou know it's blending in now what makes\n16:15\nthings blend in only lighting right so\n16:18\nthat got fixed so you don't have to run\n16:20\na separate uh sampling step right so\n16:24\nthere is a separate way to do this uh\n16:26\nbackground conditioning and everything\n16:29\nbut the way we are doing is quite\n16:30\ndifferent we are just introducing uh IP\n16:32\nadapter um because I just want to give a\n16:35\nreference image I don't want to uh do a\n16:37\nproper background uh sort of\n16:41\nsetting okay now let's run this uh\n16:43\nenough talking let's run this let's see\n16:47\nhow we can uh add some lighting on this\n16:51\nperson so let's say I want uh right side\n16:55\nleft side lighting okay let me put\n17:01\nthis\n17:04\nand\n17:06\nyep and I'll save\n17:13\nthis\n17:15\nokay uh photo of a man in a living room\n17:19\nlet me add\n17:20\n[Music]\n17:22\num see uh without yellow there there was\n17:25\nno yellow shirt so you see right it was\n17:27\nchanging the uh the\n17:30\ncolor yellow\n17:32\nshirt black\n17:35\npants black\n17:38\npants let's\n17:44\nsee so you can see the mask is\n17:48\ngenerated through the KJ nodes uh this\n17:52\nuh this node grow mask by with blur\n17:55\nresize mask through this\n18:01\nand\n18:02\nvoila there you\n18:06\ngo so uh now you can see right this uh\n18:10\nbackground image is coming from sort of\n18:14\nthis let you can also try with you know\n18:17\nwithout uh this of course let me try to\n18:20\nput this person in a let me let me\n18:22\nbypass this node for now let me try to\n18:25\nput this person in a garden or something\n18:28\nfor man in a\n18:34\ngarden\n18:55\nyeah yep beautiful\n18:59\nit's looking very good although the\n19:02\ncolor again is changing but it's it's\n19:05\ncoming out really well actually uh if I\n19:08\nwere to just look at it from uh a beauty\n19:12\nperspective it's coming out really\n19:17\nwell okay so that is IC light for you\n19:21\nguys and uh you can also uh I'll share\n19:26\nthis workflow in the chat in the\n19:29\nin the description of this video you can\n19:31\ngo ahead run this workflow on your end\n19:34\nthe best way to run any workflow is to\n19:35\njust load that workflow use manager to\n19:39\ninstall uh comfy manager to install your\n19:42\nuh Missing nodes and\n19:44\nmodels and you know just experiment\n19:47\nfurther so thanks again guys uh do not\n19:50\nforget to subscribe to flow scale uh we\n19:54\nwill we are posting uh different uh you\n19:57\nknow new innovations that are happening\n20:00\nin this space and how it can benefit\n20:03\ndifferent people uh so just tune in and\n20:06\nuh more interesting stuff coming uh\n20:08\nalong the lines thanks guys"
            ]
        },
        {
            "id": 21,
            "type": "PromptUtilitiesConstStringMultiLine",
            "pos": [
                215.91491578254113,
                317.45792162179646
            ],
            "size": {
                "0": 400,
                "1": 200
            },
            "flags": {},
            "order": 1,
            "mode": 0,
            "outputs": [
                {
                    "name": "STRING",
                    "type": "STRING",
                    "links": [
                        22
                    ],
                    "slot_index": 0,
                    "shape": 3
                }
            ],
            "properties": {
                "Node name for S&R": "PromptUtilitiesConstStringMultiLine"
            },
            "widgets_values": [
                "You are an excellent marketer who is an expert in posting linkedin content. You can create linkedin post with good combinations of emojis, etc.\n\nYou are given the task of taking the summary of a video transcript and then create the best possible linkedin content out of it. \n\nPlease refer to the summary in the prompt"
            ]
        },
        {
            "id": 22,
            "type": "ShowText|pysssss",
            "pos": [
                1299.6192441182905,
                -94.12938368113794
            ],
            "size": {
                "0": 564.3334350585938,
                "1": 270.7042541503906
            },
            "flags": {},
            "order": 8,
            "mode": 0,
            "inputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "link": 23,
                    "widget": {
                        "name": "text"
                    }
                }
            ],
            "outputs": [
                {
                    "name": "STRING",
                    "type": "STRING",
                    "links": null,
                    "shape": 6
                }
            ],
            "properties": {
                "Node name for S&R": "ShowText|pysssss"
            },
            "widgets_values": [
                "",
                " **Executive Summary**\n\n* IC Light is a new project that allows for manipulation of image illumination in a realistic manner.\n* It can automatically take the foreground out of an image and generate a new image based on the prompt and directional light provided.\n* IC Light is available on Hugging Face and GitHub, with three models available. The FC IC Light UNCORE SD15 UNCORE FC.safe tensors model is the best performing.\n\n"
            ]
        },
        {
            "id": 19,
            "type": "PromptUtilitiesConstStringMultiLine",
            "pos": [
                -176.38075588170977,
                -121.12938368113794
            ],
            "size": {
                "0": 400,
                "1": 200
            },
            "flags": {},
            "order": 2,
            "mode": 0,
            "outputs": [
                {
                    "name": "STRING",
                    "type": "STRING",
                    "links": [
                        19
                    ],
                    "shape": 3
                }
            ],
            "properties": {
                "Node name for S&R": "PromptUtilitiesConstStringMultiLine"
            },
            "widgets_values": [
                "0:01\nhello everyone this is Amon here from\n0:03\nflow scale and in this video I'm going\n0:07\nto be talking about uh IC light\n0:10\nsomething that has recently just come up\n0:12\nin uh uh and sort of is taking a lot of\n0:16\npeople by uh surprise because something\n0:19\nnow is possible which was not really\n0:22\npossible with\n0:24\num with a a stable diffusion which is to\n0:28\nbe able to adjust light in a fashion\n0:30\nthat is very\n0:32\nrealistic now uh we let's deep Let's uh\n0:35\ndig deep into that in this video but\n0:37\nbefore that uh uh if you want to reach\n0:40\nme out you can find me on Twitter with @\n0:42\nnerdycap\n0:44\n007 and uh I usually post about uh comfy\n0:48\nand uh uh how to work around comfy\n0:51\noptimizations on comfy and a lot of\n0:53\ninteresting stuff so let's get into\n0:57\nit so comfy you u i has this new even\n1:02\nbefore we lap into comfy UI let's talk\n1:06\nabout IC light\n1:09\nfirst so what is icite uh icite is a\n1:12\nproject to manipulate the illuminations\n1:14\nof image you can uh illuminate an image\n1:16\nin different fashion and uh not only\n1:19\nthat uh it is um it allows you to you\n1:23\nknow sort of add backgrounds and uh do\n1:25\nstuff with uh of by fixing a foreground\n1:28\nit it allows you to you know add\n1:30\nbackground and do a lot of stuff over\n1:31\nthere so to just give you an example\n1:35\nlike uh let's say this is an input image\n1:39\nuh you uh it automatically takes the\n1:41\nforeground out and uh uh uh based on the\n1:45\nprompt that you have provided and the\n1:46\ndirectional uh light that you have\n1:48\nprovided you can generate this sort of\n1:51\nimage now we'll experiment more with it\n1:55\num right now it has been launched on uh\n1:58\nboth on hugging phas and also on GitHub\n2:01\nthere are three models over here uh this\n2:05\none the FC IC light uncore sd15 uncore\n2:10\nfc. safe tensors is the one which is the\n2:13\nbest performing\n2:15\nmodel so we will uh use that across but\n2:19\nuh let's go through their um uh hugging\n2:22\nface space let's let's try this out\n2:25\nbefore we uh move on to comfy UI\n2:30\nso let me let me pick an image whom\n2:33\nshall we try let's try Jason mumua I\n2:36\nhave an image of Jason mumua\n2:38\nhere let's try Right\n2:41\nlight okay so they also have a few\n2:46\num uh options to select out of here\n2:49\nwhere which you can use as an example uh\n2:52\nbut let's let's see I I want to try\n2:54\nsomething on my own though\n2:58\num\n3:00\nman standing on a\n3:04\nbeach uh soft\n3:07\nsunlight I have put Right light let's\n3:10\nlet's try to relight this\n3:31\nvery\n3:33\ninteresting now if you take a look uh\n3:37\nthe light is so natural as if it's a\n3:40\nit's an image which was uh you know shot\n3:42\non a\n3:43\nbeach but uh there are a few like\n3:47\ndrawbacks to this process uh if you see\n3:50\nlike the distortions are happening a\n3:52\nlittle bit on the face and it's changing\n3:54\nthe details to some level although I I\n3:57\nmean real big kudos to\n4:00\nthe way they are uh still maintaining\n4:03\nthe details probably I guessing there's\n4:06\na\n4:07\ngood um sort of effort gone into just\n4:11\nretaining the details now this uh look\n4:14\nat this the hair and every everything is\n4:17\nso natural here the now right now these\n4:21\ndetails maybe are changing a little bit\n4:24\nbut I'm pretty much sure in the in the\n4:26\nuh in the uh later versions with of IC\n4:29\nlight we are going to be seeing like\n4:30\nreally amazing progress\n4:32\nthere so let's let's try a few few more\n4:36\nthings um and\n4:38\nstanding\n4:40\nin a living\n4:43\nroom um soft sunlight Through the\n4:48\nWindows coming through the\n4:51\nwindows let's let's put uh left light\n4:54\nthis time let's try\n5:05\no\n5:06\nnice but you can see uh the details of\n5:09\nthe clothing are changing like uh more\n5:13\nthan the details the coloring of the\n5:14\nclothing are\n5:15\nchanging so as as I already said like\n5:19\nit's\n5:20\nretaining things to a good level but\n5:23\nstill there is um there is a lot of\n5:27\nimprovement that needs to happen in\n5:29\nterms of uh retaining the identity to uh\n5:34\nits\n5:36\nfullest um they also like have a bunch\n5:39\nof examples you can try out here where\n5:42\nuh\n5:43\nthe they also have the seed and\n5:45\neverything here but uh so these I\n5:48\ngenerally when I try out uh um any new\n5:53\nuh you know uh space or any new model\n5:56\nthat gets launched I don't don't try\n5:58\nthere uh generic test data because it's\n6:02\nit's their best performing data you\n6:04\nalready know that right so it's better\n6:06\nto try out on your own uh inputs and uh\n6:09\nsee the uh how how exactly is the model\n6:13\nperforming so uh I think that's pretty\n6:16\nmuch it there are a few more options\n6:19\nAdvanced options here you can move\n6:21\naround the steps more steps let's maybe\n6:23\ntry\n6:24\nwith um 30\n6:30\n35 maybe let's let's try with\n6:34\n35 I don't usually go above 30 because\n6:37\nuh 30 is like enough uh for the number\n6:42\nof steps usually for me but let's\n6:45\nsee I'm just trying to see if uh we can\n6:49\nretain the these details which I'm\n6:51\ntalking about if we increase the steps\n6:53\nmaybe it retains it more who knows but\n6:57\nsee working with stable diffusion or any\n6:59\nuh thing like that is like uh shooting\n7:02\nan arrow in the dark but as you can see\n7:05\nlike it's again not retaining the\n7:08\nuh um the clothing but clothing not\n7:12\nbeing retained can be fixed a little bit\n7:14\nto a good certain uh level so if I um if\n7:18\nI go here and let me let me put pull\n7:22\nthis image out man standing in a living\n7:25\nroom um okay let's let's go through the\n7:28\nsame one actually let me relight this\n7:38\ndude oh my God\n7:41\nokay this is another uh issue here as\n7:45\nwell like it's darkening the uh the\n7:49\nperson the foreground a lot I don't know\n7:51\nhow to fix that\n7:53\nhere okay but but uh now if you see the\n7:57\nimage the the the the t-shirt is getting\n7:59\na little whitish over here let's let's\n8:01\ntry adding\n8:08\nthat actually yellow shirt um and black\n8:13\npants let's try adding\n8:26\nthat there you go uh so as you see right\n8:30\nuh you can do a lot of stuff like you\n8:32\ncan do uh um uh if there's a major use\n8:37\ncase of this in\n8:39\nfashion uh industry uh I mean the output\n8:43\nright now which you're seeing I'm pretty\n8:45\nmuch sure they are using an SD 1.5 model\n8:48\nat this point I guess I can just tell\n8:50\nfrom seeing the outputs but uh and also\n8:53\nwe are also using SD 1.5 in the comi\n8:56\nworkflows that I'm going to be showing\n8:58\nyou right after this but uh the the\n9:03\noutput uh here is good it is retaining\n9:06\nthe details the the texture and the\n9:09\nstructure of uh the clothing and the\n9:12\nperson uh as if it would happen like if\n9:15\nyou are using canny Edge detector to a\n9:18\nvery good level this something like this\n9:20\nyou would\n9:21\nsee but uh it's still changing the\n9:24\ndetails a little bit I'm pretty much\n9:26\nsure that will also improve as I already\n9:28\nsaid but uh\n9:30\nyou see right to a good level you can\n9:32\nsolve these issues by specifying the\n9:35\ncolor of the shirt pant and you know\n9:37\nspecific\n9:38\ndetails but um yeah there's a there's a\n9:43\nchance you will hit a roadblock uh when\n9:46\nwhen it's like any any sort of complex\n9:49\nclothing uh that's where you will hit a\n9:51\nroadblock\n9:52\nhere okay so let's see how we can use\n9:57\nthis in our comfy workflows what can we\n10:00\ndo here so to move on to the comfy side\n10:04\nI want to show you the\n10:07\ncomfy node that we're going to be using\n10:10\nit's comfy UI IC\n10:12\nlight and it is like uh pretty new 3 4\n10:17\ndays ago or probably last week people\n10:20\nhave been working on this very very new\n10:23\nso and they also specified some of the\n10:26\nexample workflows require the very\n10:28\nlatest featur features in KJ nodes so if\n10:31\nif you try out their example workflows\n10:34\nprobably just have KJ nodes I also have\n10:36\ninstalled KJ nodes it is mostly used for\n10:40\nthis uh lighting setup I'll show you\n10:42\nthat\n10:44\num yeah so let's let's uh dig deep into\n10:47\nthis I've already set up a a workflow\n10:50\nwhich I'll attach in the description of\n10:52\nthis video you can go through that and\n10:55\nlet's uh let's try to see what what we\n10:57\ncan achieve here\n11:00\nso uh just to explain the workflow uh\n11:03\nthis is the input image which I am\n11:05\ntaking in and uh first of all I'm using\n11:09\nuh image remg uh for removing the\n11:12\nbackground and just isolating the\n11:14\nforeground and uh after that that image\n11:18\nis being resized while also keeping\n11:21\nproportions which is very important if\n11:24\nyou lose the proportion it'll be well\n11:26\nyou'll lose the proportion so\n11:30\num uh after that this aspect resize mask\n11:35\nis coming from the mask area of this\n11:38\nI'll show you how exactly am I using\n11:41\nthis and then uh the output from this\n11:43\nthe mask that is being created is going\n11:44\ninto grow mask with blur these two nodes\n11:47\nare from KJ nodes and then we are\n11:49\nconverting it uh converting The Mask to\n11:52\nimage just to show case\n11:56\nhere and uh uh to Showcase here and also\n12:00\nwe are putting that in vaen code here\n12:03\nwhich is eventually going into a k\n12:05\nsampler\n12:08\nnow apart from that uh we are also using\n12:13\nas a base model we are using epic\n12:15\nrealism SD 1.5 model which is this\n12:19\nmodel the uh one uh which has been there\n12:24\nfor a while now\n12:27\nand that I'm connecting\n12:29\nto the load and apply IC light uh node\n12:35\nin which we are loading uh the sd15 FC\n12:39\nyou can download this uh uh uh this and\n12:42\nalso there is IC light conditioning you\n12:44\ncan download these models in uh um\n12:46\ncustom nodes right out of comfy so if\n12:49\nyou open comfy and uh let me check out\n12:52\nsee IC light uh if you just search IC\n12:55\nhyphen light you can find out this node\n12:57\ncomi IC light and you can directly\n12:59\ninstall this and if you want to install\n13:03\nthe models you can go and search I see\n13:07\nlight uh and you'll find all the three\n13:10\nmodels all three models have different\n13:12\npurposes but uh I generally I'm using uh\n13:16\nthe one which has FC because uh it's\n13:20\nwritten on their GitHub page that that's\n13:22\nthe one which is the most uh best\n13:24\nperforming uh model out of their uh uh\n13:27\ndifferent uh options\n13:32\nso uh the multiplier uh I'm not very\n13:35\nsure what exactly does it do but uh what\n13:39\nI found is like around. 2 183 or\n13:42\nwhatever at that uh uh number it's\n13:45\nworking decently\n13:48\nfine um there are some negative uh\n13:52\nnegative embeddings and negative uh um\n13:55\nuh prompts that I've given here and also\n13:57\nsome positive prompts which I have\n13:59\nconnected here uh\n14:02\nhere and\n14:04\neventually the K sampler throws an\n14:06\noutput VA decodes VA decode happens and\n14:10\nyou see the output here okay now let's\n14:12\ntry uh running with this also one more\n14:16\nuh thing which you won't find in the uh\n14:20\nin the uh hugging face space demo is\n14:23\nthat uh I have also introduced a IP\n14:26\nadapter here so that is a a good thing\n14:29\nuh that we can do like that's that's the\n14:32\ngood thing about comfi you have a lot of\n14:34\nfreedom in comi you can do a lot of\n14:35\nstuff so right now what I'm doing here\n14:37\nis I have introduced\n14:39\na uh IP adapter for uh giving a\n14:43\nreference image for the background right\n14:46\nso uh I'm doing something like that now\n14:48\nthis is not the traditional way to uh do\n14:51\nthe background based uh relighting on uh\n14:55\nIC light there is a separate way to uh\n14:59\nproperly uh you know uh overlay\n15:02\nsomething on a background but the\n15:04\nproblem in this is it just you know puts\n15:06\nthe person the foreground on this back\n15:09\nit takes this as a background and this\n15:11\ntakes this as a foreground and just puts\n15:13\nit on top of this right so I mean that\n15:18\nis doable but eventually it will look\n15:20\nquite fake to be very honest so uh but\n15:24\nbut the good thing is this is if you if\n15:27\nyou really look at it this is like in\n15:29\npainting on\n15:30\nsteroids because in painting so far has\n15:33\nbeen only\n15:35\num uh this is not particularly in\n15:38\npainting this is more like cut uh\n15:40\ncutting and pasting by mask or so in the\n15:43\nprevious previous uh you know uh uh um\n15:48\niterations if you if you did something\n15:50\nyou would be doing cutting and pasting\n15:52\nby mask but right now um you can do it\n15:56\nwith the lighting and everything in\n15:57\nplace this is so awesome otherwise what\n16:00\nusually used to happen is you cut by\n16:01\nmask and paste this dude here and then\n16:04\nyou run a k sampler on top of the final\n16:06\noutput uh final image to with a very\n16:09\nless denoising strength to make it as if\n16:11\nyou know it's blending in now what makes\n16:15\nthings blend in only lighting right so\n16:18\nthat got fixed so you don't have to run\n16:20\na separate uh sampling step right so\n16:24\nthere is a separate way to do this uh\n16:26\nbackground conditioning and everything\n16:29\nbut the way we are doing is quite\n16:30\ndifferent we are just introducing uh IP\n16:32\nadapter um because I just want to give a\n16:35\nreference image I don't want to uh do a\n16:37\nproper background uh sort of\n16:41\nsetting okay now let's run this uh\n16:43\nenough talking let's run this let's see\n16:47\nhow we can uh add some lighting on this\n16:51\nperson so let's say I want uh right side\n16:55\nleft side lighting okay let me put\n17:01\nthis\n17:04\nand\n17:06\nyep and I'll save\n17:13\nthis\n17:15\nokay uh photo of a man in a living room\n17:19\nlet me add\n17:20\n[Music]\n17:22\num see uh without yellow there there was\n17:25\nno yellow shirt so you see right it was\n17:27\nchanging the uh the\n17:30\ncolor yellow\n17:32\nshirt black\n17:35\npants black\n17:38\npants let's\n17:44\nsee so you can see the mask is\n17:48\ngenerated through the KJ nodes uh this\n17:52\nuh this node grow mask by with blur\n17:55\nresize mask through this\n18:01\nand\n18:02\nvoila there you\n18:06\ngo so uh now you can see right this uh\n18:10\nbackground image is coming from sort of\n18:14\nthis let you can also try with you know\n18:17\nwithout uh this of course let me try to\n18:20\nput this person in a let me let me\n18:22\nbypass this node for now let me try to\n18:25\nput this person in a garden or something\n18:28\nfor man in a\n18:34\ngarden\n18:55\nyeah yep beautiful\n18:59\nit's looking very good although the\n19:02\ncolor again is changing but it's it's\n19:05\ncoming out really well actually uh if I\n19:08\nwere to just look at it from uh a beauty\n19:12\nperspective it's coming out really\n19:17\nwell okay so that is IC light for you\n19:21\nguys and uh you can also uh I'll share\n19:26\nthis workflow in the chat in the\n19:29\nin the description of this video you can\n19:31\ngo ahead run this workflow on your end\n19:34\nthe best way to run any workflow is to\n19:35\njust load that workflow use manager to\n19:39\ninstall uh comfy manager to install your\n19:42\nuh Missing nodes and\n19:44\nmodels and you know just experiment\n19:47\nfurther so thanks again guys uh do not\n19:50\nforget to subscribe to flow scale uh we\n19:54\nwill we are posting uh different uh you\n19:57\nknow new innovations that are happening\n20:00\nin this space and how it can benefit\n20:03\ndifferent people uh so just tune in and\n20:06\nuh more interesting stuff coming uh\n20:08\nalong the lines thanks guys"
            ]
        },
        {
            "id": 17,
            "type": "Bedrock - Prompt Enhancer",
            "pos": [
                283.91491578254113,
                -257.54207837820354
            ],
            "size": {
                "0": 392.2048034667969,
                "1": 361.1207580566406
            },
            "flags": {},
            "order": 4,
            "mode": 0,
            "inputs": [
                {
                    "name": "prompt",
                    "type": "STRING",
                    "link": 19,
                    "widget": {
                        "name": "prompt"
                    }
                }
            ],
            "outputs": [
                {
                    "name": "STRING",
                    "type": "STRING",
                    "links": [
                        21,
                        23
                    ],
                    "slot_index": 0
                }
            ],
            "properties": {
                "Node name for S&R": "Bedrock - Prompt Enhancer"
            },
            "widgets_values": [
                "Format the raw transcript of a video, provided, into a structured document that will drive our content marketing pipeline. Focus on these key areas:\n\n1. Executive summary (3-5 bullet points)\n2. Sectioned content with descriptive subheadings (use markdown)\n3. Highlighted technical terms and product features (bold)\n4. Brief explanations of technical concepts [in brackets]\n5. Potential social media quotes {in braces}\n6. 'Further Resources' section suggesting related content\n7. 'Content Roadmap' outlining derivative content pieces\n\nAdditionally:\n\n- Mark areas needing expansion with [EXPAND]\n- Suggest natural points for call-to-action insertions with [CTA] \n\nPrioritize clarity and structure over comprehensiveness. \n\nFollowing is the transcript of the video:\n\n",
                "0:01\nhello everyone this is Amon here from\n0:03\nflow scale and in this video I'm going\n0:07\nto be talking about uh IC light\n0:10\nsomething that has recently just come up\n0:12\nin uh uh and sort of is taking a lot of\n0:16\npeople by uh surprise because something\n0:19\nnow is possible which was not really\n0:22\npossible with\n0:24\num with a a stable diffusion which is to\n0:28\nbe able to adjust light in a fashion\n0:30\nthat is very\n0:32\nrealistic now uh we let's deep Let's uh\n0:35\ndig deep into that in this video but\n0:37\nbefore that uh uh if you want to reach\n0:40\nme out you can find me on Twitter with @\n0:42\nnerdycap\n0:44\n007 and uh I usually post about uh comfy\n0:48\nand uh uh how to work around comfy\n0:51\noptimizations on comfy and a lot of\n0:53\ninteresting stuff so let's get into\n0:57\nit so comfy you u i has this new even\n1:02\nbefore we lap into comfy UI let's talk\n1:06\nabout IC light\n1:09\nfirst so what is icite uh icite is a\n1:12\nproject to manipulate the illuminations\n1:14\nof image you can uh illuminate an image\n1:16\nin different fashion and uh not only\n1:19\nthat uh it is um it allows you to you\n1:23\nknow sort of add backgrounds and uh do\n1:25\nstuff with uh of by fixing a foreground\n1:28\nit it allows you to you know add\n1:30\nbackground and do a lot of stuff over\n1:31\nthere so to just give you an example\n1:35\nlike uh let's say this is an input image\n1:39\nuh you uh it automatically takes the\n1:41\nforeground out and uh uh uh based on the\n1:45\nprompt that you have provided and the\n1:46\ndirectional uh light that you have\n1:48\nprovided you can generate this sort of\n1:51\nimage now we'll experiment more with it\n1:55\num right now it has been launched on uh\n1:58\nboth on hugging phas and also on GitHub\n2:01\nthere are three models over here uh this\n2:05\none the FC IC light uncore sd15 uncore\n2:10\nfc. safe tensors is the one which is the\n2:13\nbest performing\n2:15\nmodel so we will uh use that across but\n2:19\nuh let's go through their um uh hugging\n2:22\nface space let's let's try this out\n2:25\nbefore we uh move on to comfy UI\n2:30\nso let me let me pick an image whom\n2:33\nshall we try let's try Jason mumua I\n2:36\nhave an image of Jason mumua\n2:38\nhere let's try Right\n2:41\nlight okay so they also have a few\n2:46\num uh options to select out of here\n2:49\nwhere which you can use as an example uh\n2:52\nbut let's let's see I I want to try\n2:54\nsomething on my own though\n2:58\num\n3:00\nman standing on a\n3:04\nbeach uh soft\n3:07\nsunlight I have put Right light let's\n3:10\nlet's try to relight this\n3:31\nvery\n3:33\ninteresting now if you take a look uh\n3:37\nthe light is so natural as if it's a\n3:40\nit's an image which was uh you know shot\n3:42\non a\n3:43\nbeach but uh there are a few like\n3:47\ndrawbacks to this process uh if you see\n3:50\nlike the distortions are happening a\n3:52\nlittle bit on the face and it's changing\n3:54\nthe details to some level although I I\n3:57\nmean real big kudos to\n4:00\nthe way they are uh still maintaining\n4:03\nthe details probably I guessing there's\n4:06\na\n4:07\ngood um sort of effort gone into just\n4:11\nretaining the details now this uh look\n4:14\nat this the hair and every everything is\n4:17\nso natural here the now right now these\n4:21\ndetails maybe are changing a little bit\n4:24\nbut I'm pretty much sure in the in the\n4:26\nuh in the uh later versions with of IC\n4:29\nlight we are going to be seeing like\n4:30\nreally amazing progress\n4:32\nthere so let's let's try a few few more\n4:36\nthings um and\n4:38\nstanding\n4:40\nin a living\n4:43\nroom um soft sunlight Through the\n4:48\nWindows coming through the\n4:51\nwindows let's let's put uh left light\n4:54\nthis time let's try\n5:05\no\n5:06\nnice but you can see uh the details of\n5:09\nthe clothing are changing like uh more\n5:13\nthan the details the coloring of the\n5:14\nclothing are\n5:15\nchanging so as as I already said like\n5:19\nit's\n5:20\nretaining things to a good level but\n5:23\nstill there is um there is a lot of\n5:27\nimprovement that needs to happen in\n5:29\nterms of uh retaining the identity to uh\n5:34\nits\n5:36\nfullest um they also like have a bunch\n5:39\nof examples you can try out here where\n5:42\nuh\n5:43\nthe they also have the seed and\n5:45\neverything here but uh so these I\n5:48\ngenerally when I try out uh um any new\n5:53\nuh you know uh space or any new model\n5:56\nthat gets launched I don't don't try\n5:58\nthere uh generic test data because it's\n6:02\nit's their best performing data you\n6:04\nalready know that right so it's better\n6:06\nto try out on your own uh inputs and uh\n6:09\nsee the uh how how exactly is the model\n6:13\nperforming so uh I think that's pretty\n6:16\nmuch it there are a few more options\n6:19\nAdvanced options here you can move\n6:21\naround the steps more steps let's maybe\n6:23\ntry\n6:24\nwith um 30\n6:30\n35 maybe let's let's try with\n6:34\n35 I don't usually go above 30 because\n6:37\nuh 30 is like enough uh for the number\n6:42\nof steps usually for me but let's\n6:45\nsee I'm just trying to see if uh we can\n6:49\nretain the these details which I'm\n6:51\ntalking about if we increase the steps\n6:53\nmaybe it retains it more who knows but\n6:57\nsee working with stable diffusion or any\n6:59\nuh thing like that is like uh shooting\n7:02\nan arrow in the dark but as you can see\n7:05\nlike it's again not retaining the\n7:08\nuh um the clothing but clothing not\n7:12\nbeing retained can be fixed a little bit\n7:14\nto a good certain uh level so if I um if\n7:18\nI go here and let me let me put pull\n7:22\nthis image out man standing in a living\n7:25\nroom um okay let's let's go through the\n7:28\nsame one actually let me relight this\n7:38\ndude oh my God\n7:41\nokay this is another uh issue here as\n7:45\nwell like it's darkening the uh the\n7:49\nperson the foreground a lot I don't know\n7:51\nhow to fix that\n7:53\nhere okay but but uh now if you see the\n7:57\nimage the the the the t-shirt is getting\n7:59\na little whitish over here let's let's\n8:01\ntry adding\n8:08\nthat actually yellow shirt um and black\n8:13\npants let's try adding\n8:26\nthat there you go uh so as you see right\n8:30\nuh you can do a lot of stuff like you\n8:32\ncan do uh um uh if there's a major use\n8:37\ncase of this in\n8:39\nfashion uh industry uh I mean the output\n8:43\nright now which you're seeing I'm pretty\n8:45\nmuch sure they are using an SD 1.5 model\n8:48\nat this point I guess I can just tell\n8:50\nfrom seeing the outputs but uh and also\n8:53\nwe are also using SD 1.5 in the comi\n8:56\nworkflows that I'm going to be showing\n8:58\nyou right after this but uh the the\n9:03\noutput uh here is good it is retaining\n9:06\nthe details the the texture and the\n9:09\nstructure of uh the clothing and the\n9:12\nperson uh as if it would happen like if\n9:15\nyou are using canny Edge detector to a\n9:18\nvery good level this something like this\n9:20\nyou would\n9:21\nsee but uh it's still changing the\n9:24\ndetails a little bit I'm pretty much\n9:26\nsure that will also improve as I already\n9:28\nsaid but uh\n9:30\nyou see right to a good level you can\n9:32\nsolve these issues by specifying the\n9:35\ncolor of the shirt pant and you know\n9:37\nspecific\n9:38\ndetails but um yeah there's a there's a\n9:43\nchance you will hit a roadblock uh when\n9:46\nwhen it's like any any sort of complex\n9:49\nclothing uh that's where you will hit a\n9:51\nroadblock\n9:52\nhere okay so let's see how we can use\n9:57\nthis in our comfy workflows what can we\n10:00\ndo here so to move on to the comfy side\n10:04\nI want to show you the\n10:07\ncomfy node that we're going to be using\n10:10\nit's comfy UI IC\n10:12\nlight and it is like uh pretty new 3 4\n10:17\ndays ago or probably last week people\n10:20\nhave been working on this very very new\n10:23\nso and they also specified some of the\n10:26\nexample workflows require the very\n10:28\nlatest featur features in KJ nodes so if\n10:31\nif you try out their example workflows\n10:34\nprobably just have KJ nodes I also have\n10:36\ninstalled KJ nodes it is mostly used for\n10:40\nthis uh lighting setup I'll show you\n10:42\nthat\n10:44\num yeah so let's let's uh dig deep into\n10:47\nthis I've already set up a a workflow\n10:50\nwhich I'll attach in the description of\n10:52\nthis video you can go through that and\n10:55\nlet's uh let's try to see what what we\n10:57\ncan achieve here\n11:00\nso uh just to explain the workflow uh\n11:03\nthis is the input image which I am\n11:05\ntaking in and uh first of all I'm using\n11:09\nuh image remg uh for removing the\n11:12\nbackground and just isolating the\n11:14\nforeground and uh after that that image\n11:18\nis being resized while also keeping\n11:21\nproportions which is very important if\n11:24\nyou lose the proportion it'll be well\n11:26\nyou'll lose the proportion so\n11:30\num uh after that this aspect resize mask\n11:35\nis coming from the mask area of this\n11:38\nI'll show you how exactly am I using\n11:41\nthis and then uh the output from this\n11:43\nthe mask that is being created is going\n11:44\ninto grow mask with blur these two nodes\n11:47\nare from KJ nodes and then we are\n11:49\nconverting it uh converting The Mask to\n11:52\nimage just to show case\n11:56\nhere and uh uh to Showcase here and also\n12:00\nwe are putting that in vaen code here\n12:03\nwhich is eventually going into a k\n12:05\nsampler\n12:08\nnow apart from that uh we are also using\n12:13\nas a base model we are using epic\n12:15\nrealism SD 1.5 model which is this\n12:19\nmodel the uh one uh which has been there\n12:24\nfor a while now\n12:27\nand that I'm connecting\n12:29\nto the load and apply IC light uh node\n12:35\nin which we are loading uh the sd15 FC\n12:39\nyou can download this uh uh uh this and\n12:42\nalso there is IC light conditioning you\n12:44\ncan download these models in uh um\n12:46\ncustom nodes right out of comfy so if\n12:49\nyou open comfy and uh let me check out\n12:52\nsee IC light uh if you just search IC\n12:55\nhyphen light you can find out this node\n12:57\ncomi IC light and you can directly\n12:59\ninstall this and if you want to install\n13:03\nthe models you can go and search I see\n13:07\nlight uh and you'll find all the three\n13:10\nmodels all three models have different\n13:12\npurposes but uh I generally I'm using uh\n13:16\nthe one which has FC because uh it's\n13:20\nwritten on their GitHub page that that's\n13:22\nthe one which is the most uh best\n13:24\nperforming uh model out of their uh uh\n13:27\ndifferent uh options\n13:32\nso uh the multiplier uh I'm not very\n13:35\nsure what exactly does it do but uh what\n13:39\nI found is like around. 2 183 or\n13:42\nwhatever at that uh uh number it's\n13:45\nworking decently\n13:48\nfine um there are some negative uh\n13:52\nnegative embeddings and negative uh um\n13:55\nuh prompts that I've given here and also\n13:57\nsome positive prompts which I have\n13:59\nconnected here uh\n14:02\nhere and\n14:04\neventually the K sampler throws an\n14:06\noutput VA decodes VA decode happens and\n14:10\nyou see the output here okay now let's\n14:12\ntry uh running with this also one more\n14:16\nuh thing which you won't find in the uh\n14:20\nin the uh hugging face space demo is\n14:23\nthat uh I have also introduced a IP\n14:26\nadapter here so that is a a good thing\n14:29\nuh that we can do like that's that's the\n14:32\ngood thing about comfi you have a lot of\n14:34\nfreedom in comi you can do a lot of\n14:35\nstuff so right now what I'm doing here\n14:37\nis I have introduced\n14:39\na uh IP adapter for uh giving a\n14:43\nreference image for the background right\n14:46\nso uh I'm doing something like that now\n14:48\nthis is not the traditional way to uh do\n14:51\nthe background based uh relighting on uh\n14:55\nIC light there is a separate way to uh\n14:59\nproperly uh you know uh overlay\n15:02\nsomething on a background but the\n15:04\nproblem in this is it just you know puts\n15:06\nthe person the foreground on this back\n15:09\nit takes this as a background and this\n15:11\ntakes this as a foreground and just puts\n15:13\nit on top of this right so I mean that\n15:18\nis doable but eventually it will look\n15:20\nquite fake to be very honest so uh but\n15:24\nbut the good thing is this is if you if\n15:27\nyou really look at it this is like in\n15:29\npainting on\n15:30\nsteroids because in painting so far has\n15:33\nbeen only\n15:35\num uh this is not particularly in\n15:38\npainting this is more like cut uh\n15:40\ncutting and pasting by mask or so in the\n15:43\nprevious previous uh you know uh uh um\n15:48\niterations if you if you did something\n15:50\nyou would be doing cutting and pasting\n15:52\nby mask but right now um you can do it\n15:56\nwith the lighting and everything in\n15:57\nplace this is so awesome otherwise what\n16:00\nusually used to happen is you cut by\n16:01\nmask and paste this dude here and then\n16:04\nyou run a k sampler on top of the final\n16:06\noutput uh final image to with a very\n16:09\nless denoising strength to make it as if\n16:11\nyou know it's blending in now what makes\n16:15\nthings blend in only lighting right so\n16:18\nthat got fixed so you don't have to run\n16:20\na separate uh sampling step right so\n16:24\nthere is a separate way to do this uh\n16:26\nbackground conditioning and everything\n16:29\nbut the way we are doing is quite\n16:30\ndifferent we are just introducing uh IP\n16:32\nadapter um because I just want to give a\n16:35\nreference image I don't want to uh do a\n16:37\nproper background uh sort of\n16:41\nsetting okay now let's run this uh\n16:43\nenough talking let's run this let's see\n16:47\nhow we can uh add some lighting on this\n16:51\nperson so let's say I want uh right side\n16:55\nleft side lighting okay let me put\n17:01\nthis\n17:04\nand\n17:06\nyep and I'll save\n17:13\nthis\n17:15\nokay uh photo of a man in a living room\n17:19\nlet me add\n17:20\n[Music]\n17:22\num see uh without yellow there there was\n17:25\nno yellow shirt so you see right it was\n17:27\nchanging the uh the\n17:30\ncolor yellow\n17:32\nshirt black\n17:35\npants black\n17:38\npants let's\n17:44\nsee so you can see the mask is\n17:48\ngenerated through the KJ nodes uh this\n17:52\nuh this node grow mask by with blur\n17:55\nresize mask through this\n18:01\nand\n18:02\nvoila there you\n18:06\ngo so uh now you can see right this uh\n18:10\nbackground image is coming from sort of\n18:14\nthis let you can also try with you know\n18:17\nwithout uh this of course let me try to\n18:20\nput this person in a let me let me\n18:22\nbypass this node for now let me try to\n18:25\nput this person in a garden or something\n18:28\nfor man in a\n18:34\ngarden\n18:55\nyeah yep beautiful\n18:59\nit's looking very good although the\n19:02\ncolor again is changing but it's it's\n19:05\ncoming out really well actually uh if I\n19:08\nwere to just look at it from uh a beauty\n19:12\nperspective it's coming out really\n19:17\nwell okay so that is IC light for you\n19:21\nguys and uh you can also uh I'll share\n19:26\nthis workflow in the chat in the\n19:29\nin the description of this video you can\n19:31\ngo ahead run this workflow on your end\n19:34\nthe best way to run any workflow is to\n19:35\njust load that workflow use manager to\n19:39\ninstall uh comfy manager to install your\n19:42\nuh Missing nodes and\n19:44\nmodels and you know just experiment\n19:47\nfurther so thanks again guys uh do not\n19:50\nforget to subscribe to flow scale uh we\n19:54\nwill we are posting uh different uh you\n19:57\nknow new innovations that are happening\n20:00\nin this space and how it can benefit\n20:03\ndifferent people uh so just tune in and\n20:06\nuh more interesting stuff coming uh\n20:08\nalong the lines thanks guys"
            ]
        },
        {
            "id": 18,
            "type": "ShowText|pysssss",
            "pos": [
                2091,
                -104
            ],
            "size": {
                "0": 406.2547607421875,
                "1": 371.6215515136719
            },
            "flags": {},
            "order": 10,
            "mode": 0,
            "inputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "link": 20,
                    "widget": {
                        "name": "text"
                    }
                }
            ],
            "outputs": [
                {
                    "name": "STRING",
                    "type": "STRING",
                    "links": null,
                    "shape": 6
                }
            ],
            "properties": {
                "Node name for S&R": "ShowText|pysssss"
            },
            "widgets_values": [
                "",
                " ð¡ Introducing IC Light: the game-changing project for image manipulation! ð\n\nð Say goodbye to dull, poorly lit images and hello to vibrant, realistic illumination. IC Light can automatically extract the foreground of an image and generate a stunning new image based on your prompt and directional light preferences. ð¡ð¸\n\nð Ready to level up your image editing skills? IC Light is now available on Hugging Face and GitHub, with three powerful models to choose from. Our top recommendation: the FC IC Light UNCORE SD15 UNCORE FC.safe tensors model, which delivers unparalleled performance. ð\n\nð§ Dive in, explore the possibilities, and start creating your own visually stunning masterpieces today! ð¨â¨\n\nð Check it out now on Hugging Face: <https://huggingface.co/spaces/nateraw/IC-Light>\nð Or GitHub: <https://github.com/nateraw/IC-Light>\n\n#ICLight #ImageManipulation #AI #Photography #Design #Innovation #LinkedInCreators"
            ]
        },
        {
            "id": 11,
            "type": "CheckpointLoaderSimple",
            "pos": [
                749.9149157825411,
                830.4579216217965
            ],
            "size": {
                "0": 315,
                "1": 98
            },
            "flags": {},
            "order": 3,
            "mode": 0,
            "outputs": [
                {
                    "name": "MODEL",
                    "type": "MODEL",
                    "links": [
                        10
                    ],
                    "slot_index": 0
                },
                {
                    "name": "CLIP",
                    "type": "CLIP",
                    "links": [
                        14,
                        15
                    ],
                    "slot_index": 1
                },
                {
                    "name": "VAE",
                    "type": "VAE",
                    "links": [
                        17
                    ],
                    "slot_index": 2
                }
            ],
            "properties": {
                "Node name for S&R": "CheckpointLoaderSimple"
            },
            "widgets_values": [
                "epicrealism_naturalSinRC1VAE.safetensors"
            ]
        }
    ],
    "links": [
        [
            10,
            11,
            0,
            10,
            0,
            "MODEL"
        ],
        [
            11,
            13,
            0,
            10,
            1,
            "CONDITIONING"
        ],
        [
            12,
            14,
            0,
            10,
            2,
            "CONDITIONING"
        ],
        [
            13,
            12,
            0,
            10,
            3,
            "LATENT"
        ],
        [
            14,
            11,
            1,
            13,
            0,
            "CLIP"
        ],
        [
            15,
            11,
            1,
            14,
            0,
            "CLIP"
        ],
        [
            16,
            10,
            0,
            15,
            0,
            "LATENT"
        ],
        [
            17,
            11,
            2,
            15,
            1,
            "VAE"
        ],
        [
            18,
            15,
            0,
            16,
            0,
            "IMAGE"
        ],
        [
            19,
            19,
            0,
            17,
            0,
            "STRING"
        ],
        [
            20,
            20,
            0,
            18,
            0,
            "STRING"
        ],
        [
            21,
            17,
            0,
            20,
            0,
            "STRING"
        ],
        [
            22,
            21,
            0,
            20,
            1,
            "STRING"
        ],
        [
            23,
            17,
            0,
            22,
            0,
            "STRING"
        ]
    ],
    "groups": [],
    "config": {},
    "extra": {
        "ds": {
            "scale": 0.5644739300537773,
            "offset": [
                -150.80815660735283,
                412.8450448828913
            ]
        }
    },
    "version": 0.4
}